{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from sklearn.metrics import f1_score #f1 score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Counter({3: 692, 2: 154, 1: 101, 0: 53})\n"
     ]
    }
   ],
   "source": [
    "X,y = make_classification(n_samples=1000, n_redundant=0, n_repeated=0, n_classes=4, n_clusters_per_class=1,\n",
    "                            weights=[0.05, 0.10, 0.15, 0.7], n_features=10, random_state=100)\n",
    "print('Original Data %s' % Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Data from UnderSampling Counter({0: 53, 1: 53, 2: 53, 3: 53})\n",
      "X shape: (212, 10) , y shape: (212,)\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=100)\n",
    "rus.fit(X, y)\n",
    "X_usampled, y_usampled = rus.fit_resample(X, y)\n",
    "print('Resampled Data from UnderSampling %s' % Counter(y_usampled))\n",
    "print('X shape:',X_usampled.shape,\", y shape:\",y_usampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Data from SMOTE OverSampling Counter({2: 692, 3: 692, 1: 692, 0: 692})\n",
      "X shape: (2768, 10) , y shape: (2768,)\n",
      "Resampled Data from ADASYN OverSampling Counter({1: 694, 3: 692, 2: 689, 0: 683})\n",
      "X shape: (2758, 10) , y shape: (2758,)\n"
     ]
    }
   ],
   "source": [
    "sm=SMOTE(k_neighbors=5, random_state=100)\n",
    "X_sm, y_sm = sm.fit_resample(X,y)\n",
    "ada=ADASYN(n_neighbors=5, random_state=100)\n",
    "X_ada, y_ada = ada.fit_resample(X,y)\n",
    "print('Resampled Data from SMOTE OverSampling %s' % Counter(y_sm))\n",
    "print('X shape:',X_sm.shape,\", y shape:\",y_sm.shape)\n",
    "print('Resampled Data from ADASYN OverSampling %s' % Counter(y_ada))\n",
    "print('X shape:',X_ada.shape,\", y shape:\",y_ada.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_cv(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "    param_grid_logistic={'C':[1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]}\n",
    "    logistic_cv=GridSearchCV(LogisticRegression(penalty = 'l2'), param_grid_logistic, cv=5)\n",
    "    logistic_cv.fit(X_train,y_train)\n",
    "    print(logistic_cv.best_params_)\n",
    "    logistic_train=logistic_cv.predict(X_train)\n",
    "    logistic_test=logistic_cv.predict(X_test)\n",
    "    print(\"Train:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_train,logistic_train),2),'   /' ,\n",
    "          round(recall_score(y_train, logistic_train, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_train,logistic_train, average='macro'),2))\n",
    "    print(\"Test:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_test,logistic_test),2),'   /' ,\n",
    "          round(recall_score(y_test, logistic_test, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_test,logistic_test, average='macro'),2))\n",
    "    scores = cross_val_score(logistic_cv, X, y, cv=5) \n",
    "    print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.88    / 0.75    / 0.8\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.85    / 0.73    / 0.76\n",
      "CV accuracy: 0.860 +/- 0.030\n"
     ]
    }
   ],
   "source": [
    "logistic_cv(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.8    / 0.79    / 0.79\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.78    / 0.8    / 0.79\n",
      "CV accuracy: 0.751 +/- 0.072\n"
     ]
    }
   ],
   "source": [
    "logistic_cv(X_usampled,y_usampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.85    / 0.85    / 0.85\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.82    / 0.83    / 0.83\n",
      "CV accuracy: 0.839 +/- 0.022\n"
     ]
    }
   ],
   "source": [
    "logistic_cv(X_sm, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.8    / 0.8    / 0.8\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.79    / 0.8    / 0.8\n",
      "CV accuracy: 0.787 +/- 0.019\n"
     ]
    }
   ],
   "source": [
    "logistic_cv(X_ada, y_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "    lda = LinearDiscriminantAnalysis(store_covariance=False)\n",
    "    lda.fit(X_train,y_train)\n",
    "    lda_train=lda.predict(X_train)\n",
    "    lda_test=lda.predict(X_test)\n",
    "    print(\"Train:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_train,lda_train),2),'   /' ,\n",
    "          round(recall_score(y_train, lda_train, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_train,lda_train, average='macro'),2))\n",
    "    print(\"Test:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_test,lda_test),2),'   /' ,\n",
    "          round(recall_score(y_test, lda_test, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_test,lda_test, average='macro'),2))\n",
    "    scores = cross_val_score(lda, X, y, cv=5) \n",
    "    print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.84    / 0.66    / 0.68\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.82    / 0.63    / 0.65\n",
      "CV accuracy: 0.832 +/- 0.025\n"
     ]
    }
   ],
   "source": [
    "lda(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.78    / 0.76    / 0.76\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.75    / 0.77    / 0.76\n",
      "CV accuracy: 0.727 +/- 0.050\n"
     ]
    }
   ],
   "source": [
    "lda(X_usampled, y_usampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.8    / 0.8    / 0.79\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.8    / 0.8    / 0.8\n",
      "CV accuracy: 0.798 +/- 0.019\n"
     ]
    }
   ],
   "source": [
    "lda(X_sm, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.77    / 0.77    / 0.77\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.76    / 0.77    / 0.76\n",
      "CV accuracy: 0.757 +/- 0.030\n"
     ]
    }
   ],
   "source": [
    "lda(X_ada, y_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_cv(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "    param_grid_svm={'C':[10**(i+1) for i in range(-3,2)], 'gamma':[10**(i+1) for i in range(-3,2)],'kernel':['rbf','sigmoid']}\n",
    "    svm_cv=GridSearchCV(SVC(random_state=1206), param_grid_svm, cv=5)\n",
    "    svm_cv.fit(X_train,y_train)\n",
    "    print(svm_cv.best_params_)\n",
    "    svm_train=svm_cv.predict(X_train)\n",
    "    svm_test=svm_cv.predict(X_test)\n",
    "    print(\"Train:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_train,svm_train),2),'   /' ,\n",
    "          round(recall_score(y_train, svm_train, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_train,svm_train, average='macro'),2))\n",
    "    print(\"Test:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_test,svm_test),2),'   /' ,\n",
    "          round(recall_score(y_test, svm_test, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_test,svm_test, average='macro'),2))\n",
    "    scores = cross_val_score(svm_cv, X, y, cv=5) \n",
    "    print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.9    / 0.79    / 0.85\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.9    / 0.78    / 0.84\n",
      "CV accuracy: 0.887 +/- 0.028\n"
     ]
    }
   ],
   "source": [
    "svm_cv(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.8    / 0.8    / 0.8\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.84    / 0.85    / 0.85\n",
      "CV accuracy: 0.745 +/- 0.065\n"
     ]
    }
   ],
   "source": [
    "svm_cv(X_usampled, y_usampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 1.0    / 1.0    / 1.0\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.95    / 0.95    / 0.95\n",
      "CV accuracy: 0.978 +/- 0.008\n"
     ]
    }
   ],
   "source": [
    "svm_cv(X_sm, y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 1.0    / 1.0    / 1.0\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.96    / 0.96    / 0.96\n",
      "CV accuracy: 0.960 +/- 0.010\n"
     ]
    }
   ],
   "source": [
    "svm_cv(X_ada, y_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cv(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "    param_grid_rf={'criterion':[\"gini\",\"entropy\"] ,'max_features':['sqrt','log2',X_train.shape[1]]}\n",
    "    rf_cv=GridSearchCV(RandomForestClassifier(random_state=100), param_grid_rf, cv=5)\n",
    "    rf_cv.fit(X_train,y_train)\n",
    "    print(rf_cv.best_params_)\n",
    "    rf_train=rf_cv.predict(X_train)\n",
    "    rf_test=rf_cv.predict(X_test)\n",
    "    print(\"Train:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_train,rf_train),2),'   /' ,\n",
    "          round(recall_score(y_train, rf_train, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_train,rf_train, average='macro'),2))\n",
    "    print(\"Test:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_test,rf_test),2),'   /' ,\n",
    "          round(recall_score(y_test, rf_test, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_test,rf_test, average='macro'),2))\n",
    "    scores = cross_val_score(rf_cv, X, y, cv=5) \n",
    "    print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_features': 'sqrt'}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 1.0    / 1.0    / 1.0\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.92    / 0.82    / 0.87\n",
      "CV accuracy: 0.919 +/- 0.024\n"
     ]
    }
   ],
   "source": [
    "rf_cv(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_features': 10}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 1.0    / 1.0    / 1.0\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.81    / 0.82    / 0.83\n",
      "CV accuracy: 0.783 +/- 0.039\n"
     ]
    }
   ],
   "source": [
    "rf_cv(X_usampled,y_usampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_features': 10}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 1.0    / 1.0    / 1.0\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.95    / 0.95    / 0.95\n",
      "CV accuracy: 0.962 +/- 0.011\n"
     ]
    }
   ],
   "source": [
    "rf_cv(X_sm,y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_features': 'sqrt'}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 1.0    / 1.0    / 1.0\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.97    / 0.97    / 0.97\n",
      "CV accuracy: 0.938 +/- 0.032\n"
     ]
    }
   ],
   "source": [
    "rf_cv(X_ada,y_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "    param_grid_xgb={'max_depth': [3, 5, 7, 9], 'n_estimators': [5, 10, 15, 20, 25, 50, 100],'learning_rate': [0.01, 0.05, 0.1]}\n",
    "    xgb_cv=GridSearchCV(xgb.XGBClassifier(random_state=100), param_grid_xgb, cv=5)\n",
    "    xgb_cv.fit(X_train,y_train)\n",
    "    print(xgb_cv.best_params_)\n",
    "    xgb_train=xgb_cv.predict(X_train)\n",
    "    xgb_test=xgb_cv.predict(X_test)\n",
    "    print(\"Train:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_train,xgb_train),2),'   /' ,\n",
    "          round(recall_score(y_train, xgb_train, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_train,xgb_train, average='macro'),2))\n",
    "    print(\"Test:\\n\",\"Accuracy / Recall / F1 score  \\n\",round(accuracy_score(y_test,xgb_test),2),'   /' ,\n",
    "          round(recall_score(y_test, xgb_test, average='macro'),2),'   /' ,\n",
    "          round(f1_score(y_test,xgb_test, average='macro'),2))\n",
    "    scores = cross_val_score(xgb_cv, X, y, cv=5) \n",
    "    print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.97    / 0.93    / 0.95\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.92    / 0.85    / 0.89\n",
      "CV accuracy: 0.918 +/- 0.026\n"
     ]
    }
   ],
   "source": [
    "xgb_cv(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 25}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 1.0    / 1.0    / 1.0\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.78    / 0.8    / 0.79\n",
      "CV accuracy: 0.774 +/- 0.042\n"
     ]
    }
   ],
   "source": [
    "xgb_cv(X_usampled,y_usampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 1.0    / 1.0    / 1.0\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.96    / 0.96    / 0.96\n",
      "CV accuracy: 0.953 +/- 0.016\n"
     ]
    }
   ],
   "source": [
    "xgb_cv(X_sm,y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "Train:\n",
      " Accuracy / Recall / F1 score  \n",
      " 1.0    / 1.0    / 1.0\n",
      "Test:\n",
      " Accuracy / Recall / F1 score  \n",
      " 0.96    / 0.96    / 0.96\n",
      "CV accuracy: 0.930 +/- 0.023\n"
     ]
    }
   ],
   "source": [
    "xgb_cv(X_ada,y_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
